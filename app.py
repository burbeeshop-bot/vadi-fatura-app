# app.py
# === Vadi Fatura â€” BÃ¶l & Alt YazÄ± & Apsiyon & WhatsApp (Drive entegrasyonlu) ===
import io, os, re, zipfile, unicodedata, json, uuid
from typing import List, Dict, Tuple, Optional

import streamlit as st
import pandas as pd
# ---------------- GOOGLE DRIVE: Secrets ile baÄŸlan & yardÄ±mcÄ±lar ----------------
try:
    from google.oauth2 import service_account
    from googleapiclient.discovery import build
    from googleapiclient.errors import HttpError
    _GDRIVE_OK = True
except Exception:
    _GDRIVE_OK = False

import streamlit as st
import json

@st.cache_resource(show_spinner=False)
def get_drive_service_from_secrets():
    """
    Streamlit Secrets'taki [gdrive_service_account] ile Drive service oluÅŸturur.
    """
    info = st.secrets.get("gdrive_service_account")
    if not info:
        raise RuntimeError("Streamlit Secrets iÃ§inde [gdrive_service_account] yok.")
    scopes = ["https://www.googleapis.com/auth/drive"]
    creds = service_account.Credentials.from_service_account_info(info, scopes=scopes)
    service = build("drive", "v3", credentials=creds, cache_discovery=False)
    return service

def list_pdfs_in_folder(service, folder_id: str):
    """
    Verilen klasÃ¶rdeki PDF dosyalarÄ±nÄ± listeler.
    """
    files = []
    page_token = None
    query = f"'{folder_id}' in parents and mimeType='application/pdf' and trashed=false"
    while True:
        resp = service.files().list(
            q=query,
            fields="nextPageToken, files(id,name,webViewLink,webContentLink)",
            pageSize=1000,
            pageToken=page_token,
            supportsAllDrives=True,
            includeItemsFromAllDrives=True
        ).execute()
        files.extend(resp.get("files", []))
        page_token = resp.get("nextPageToken")
        if not page_token:
            break
    return files

def ensure_anyone_with_link_permission(service, file_id: str):
    """
    DosyayÄ± 'linke sahip olan gÃ¶rÃ¼ntÃ¼leyebilir' yapar (sadece dosya bazÄ±nda).
    """
    try:
        service.permissions().create(
            fileId=file_id,
            body={"role": "reader", "type": "anyone"},
            fields="id",
            supportsAllDrives=True
        ).execute()
    except HttpError:
        pass

def build_direct_file_link(file_id: str, mode: str = "download") -> str:
    """
    'download' -> doÄŸrudan indirme linki
    'view'     -> Drive gÃ¶rÃ¼ntÃ¼leme linki
    """
    if mode == "view":
        return f"https://drive.google.com/file/d/{file_id}/view?usp=drivesdk"
    else:
        return f"https://drive.google.com/uc?export=download&id={file_id}"
# PDF
from pypdf import PdfReader, PdfWriter

# ReportLab (alt yazÄ±)
from reportlab.pdfgen import canvas
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont

# (opsiyonel) .docx
try:
    import docx  # python-docx
    HAS_DOCX = True
except Exception:
    HAS_DOCX = False

# -----------------------------------------------------------------------------
# Streamlit Page
# -----------------------------------------------------------------------------
st.set_page_config(page_title="Fatura â€¢ Atlas Vadi", page_icon="ğŸ§¾", layout="wide")

# -----------------------------------------------------------------------------
# Fontlar (varsa yÃ¼kle; yoksa sessiz geÃ§sin)
# -----------------------------------------------------------------------------
try:
    pdfmetrics.registerFont(TTFont("NotoSans-Regular", "fonts/NotoSans-Regular.ttf"))
    pdfmetrics.registerFont(TTFont("NotoSans-Bold",    "fonts/NotoSans-Bold.ttf"))
except Exception:
    pass

# -----------------------------------------------------------------------------
# YardÄ±mcÄ±lar (genel)
# -----------------------------------------------------------------------------
def _pad3_digits(s: str) -> str:
    s = "".join(ch for ch in str(s) if ch.isdigit())
    return s.zfill(3) if s else "000"

def _to_float_tr(s: str) -> float:
    if not s:
        return 0.0
    s = str(s).strip().replace(".", "").replace(",", ".")
    try:
        return float(s)
    except:
        return 0.0

def _normalize_tr(t: str) -> str:
    """TÃ¼rkÃ§e aksanlarÄ± sadeleÅŸtir, bÃ¼yÃ¼k harfe Ã§evir, spacingâ€™i toparlar."""
    if not t:
        return ""
    t = unicodedata.normalize("NFKD", t)
    t = "".join(ch for ch in t if not unicodedata.combining(ch))
    t = (t.replace("Ä±","i").replace("Ä°","I")
           .replace("ÅŸ","s").replace("Å","S")
           .replace("Ã¶","o").replace("Ã–","O")
           .replace("Ã¼","u").replace("Ãœ","U")
           .replace("ÄŸ","g").replace("Ä","G")
           .replace("Ã§","c").replace("Ã‡","C"))
    t = t.upper()
    t = re.sub(r"[ \t]+", " ", t)
    return t

def _norm_colname(s: str) -> str:
    return (str(s).strip().lower()
            .replace("\n"," ").replace("\r"," ")
            .replace(".","").replace("_"," ").replace("-"," "))

# -----------------------------------------------------------------------------
# Alt YazÄ± (wrap & overlay)
# -----------------------------------------------------------------------------
def wrap_by_width(text: str, font_name: str, font_size: float, max_width: float) -> List[str]:
    lines = []
    for raw in text.replace("\r\n", "\n").replace("\r", "\n").split("\n"):
        if not raw.strip():
            lines.append("")
            continue
        words = raw.split()
        current = ""
        for w in words:
            trial = (current + " " + w).strip()
            width = pdfmetrics.stringWidth(trial, font_name, font_size)
            if width <= max_width:
                current = trial
            else:
                if current:
                    lines.append(current)
                if pdfmetrics.stringWidth(w, font_name, font_size) > max_width:
                    piece = ""
                    for ch in w:
                        if pdfmetrics.stringWidth(piece + ch, font_name, font_size) <= max_width:
                            piece += ch
                        else:
                            lines.append(piece)
                            piece = ch
                    current = piece
                else:
                    current = w
        lines.append(current)
    return lines

def build_footer_overlay(
    page_w: float,
    page_h: float,
    footer_text: str,
    font_size: int = 11,
    leading: int = 14,
    align: str = "left",  # "left" | "center"
    bottom_margin: int = 48,
    box_height: int = 180,
    bold_rules: bool = True,
) -> io.BytesIO:
    packet = io.BytesIO()
    can = canvas.Canvas(packet, pagesize=(page_w, page_h))

    left_margin = 36
    right_margin = 36
    max_text_width = page_w - left_margin - right_margin

    wrapped = wrap_by_width(footer_text, "NotoSans-Regular", font_size, max_text_width)

    max_lines = max(1, int(box_height // leading))
    if len(wrapped) > max_lines:
        wrapped = wrapped[:max_lines]

    y_start = bottom_margin + (len(wrapped) - 1) * leading + 4

    for i, line in enumerate(wrapped):
        use_bold = False
        if bold_rules:
            u = line.strip().upper()
            if i == 0 and u.startswith("SON Ã–DEME"):
                use_bold = True
            if u == "AÃ‡IKLAMA":
                use_bold = True
            if "TARÄ°HLÄ° TEMSÄ°LCÄ°LER" in u:
                use_bold = True

        can.setFont("NotoSans-Bold" if use_bold else "NotoSans-Regular", font_size)
        y = y_start - i * leading
        if align == "center":
            can.drawCentredString(page_w / 2.0, y, line)
        else:
            can.drawString(left_margin, y, line)

    can.save()
    packet.seek(0)
    return packet

def add_footer_to_pdf(src_bytes: bytes, **kw) -> bytes:
    reader = PdfReader(io.BytesIO(src_bytes))
    writer = PdfWriter()
    for page in reader.pages:
        w = float(page.mediabox.width)
        h = float(page.mediabox.height)
        overlay_io = build_footer_overlay(w, h, **kw)
        overlay = PdfReader(overlay_io)
        page.merge_page(overlay.pages[0])
        writer.add_page(page)
    out = io.BytesIO()
    writer.write(out)
    return out.getvalue()

def split_pdf(src_bytes: bytes) -> List[Tuple[str, bytes]]:
    reader = PdfReader(io.BytesIO(src_bytes))
    pages = []
    for i, p in enumerate(reader.pages, start=1):
        w = PdfWriter()
        w.add_page(p)
        b = io.BytesIO()
        w.write(b)
        pages.append((f"page_{i:03d}.pdf", b.getvalue()))
    return pages

# -----------------------------------------------------------------------------
# Daire No AlgÄ±lama & KÃ¶ÅŸe Etiketi & Yeniden AdlandÄ±rma
# -----------------------------------------------------------------------------
_re_daire_norms = [
    re.compile(r"DAIRE\s*NO[^A-Z0-9]{0,15}([A-Z]\d)[^0-9]{0,20}(\d{1,4})"),
    re.compile(r"([A-Z]\d)[^\d\n\r]{0,30}DAIRE[^0-9]{0,10}(\d{1,4})"),
]
_re_daire_raws = [
    re.compile(r"DA[Ä°I]RE\s*NO[^A-Z0-9]{0,15}([A-Z]\d)[^0-9]{0,20}(\d{1,4})"),
    re.compile(r"([A-Z]\d)[^\d\n\r]{0,30}DA[Ä°I]RE[^0-9]{0,10}(\d{1,4})"),
]

def _find_daire_id(raw_text: str) -> Optional[str]:
    norm = _normalize_tr(raw_text)
    for rx in _re_daire_norms:
        m = rx.search(norm)
        if m:
            blok = m.group(1).upper()
            dno  = _pad3_digits(m.group(2))
            return f"{blok}-{dno}"
    for rx in _re_daire_raws:
        m = rx.search(raw_text)
        if m:
            blok = m.group(1).upper()
            dno  = _pad3_digits(m.group(2))
            return f"{blok}-{dno}"
    return None

def build_corner_label_overlay(
    page_w: float, page_h: float, label_text: str,
    font_size: int = 13, bold: bool = True,
    position: str = "TR", pad_x: int = 20, pad_y: int = 20
) -> io.BytesIO:
    packet = io.BytesIO()
    can = canvas.Canvas(packet, pagesize=(page_w, page_h))
    font_name = "NotoSans-Bold" if bold else "NotoSans-Regular"
    can.setFont(font_name, font_size)
    text_w = pdfmetrics.stringWidth(label_text, font_name, font_size)
    text_h = font_size * 1.2

    if position == "TR":
        x = page_w - pad_x - text_w
        y = page_h - pad_y - text_h
    elif position == "TL":
        x = pad_x
        y = page_h - pad_y - text_h
    elif position == "BR":
        x = page_w - pad_x - text_w
        y = pad_y
    else:  # BL
        x = pad_x
        y = pad_y

    can.drawString(x, y, label_text)
    can.save()
    packet.seek(0)
    return packet

def add_footer_and_stamp_per_page(
    src_bytes: bytes,
    footer_kwargs: dict,
    stamp_on: bool,
    label_tpl: str,
    stamp_opts: dict,
    rename_files: bool
) -> List[Tuple[str, bytes]]:
    reader = PdfReader(io.BytesIO(src_bytes))
    out_pages: List[Tuple[str, bytes]] = []

    for i, page in enumerate(reader.pages, start=1):
        w = float(page.mediabox.width)
        h = float(page.mediabox.height)

        # footer
        footer_overlay_io = build_footer_overlay(w, h, **footer_kwargs)
        footer_overlay = PdfReader(footer_overlay_io)
        page.merge_page(footer_overlay.pages[0])

        # DaireID
        daire_id = None
        try:
            txt = page.extract_text() or ""
            daire_id = _find_daire_id(txt)
        except Exception:
            daire_id = None

        # kÃ¶ÅŸe etiketi
        if stamp_on and daire_id:
            label_text = label_tpl.format(daire_id=daire_id)
            label_overlay_io = build_corner_label_overlay(
                w, h, label_text,
                font_size=stamp_opts.get("font_size", 13),
                bold=stamp_opts.get("bold", True),
                position=stamp_opts.get("position", "TR"),
                pad_x=stamp_opts.get("pad_x", 20),
                pad_y=stamp_opts.get("pad_y", 20),
            )
            label_overlay = PdfReader(label_overlay_io)
            page.merge_page(label_overlay.pages[0])

        # tek sayfa pdf
        wri = PdfWriter()
        wri.add_page(page)
        buf = io.BytesIO()
        wri.write(buf)
        buf.seek(0)

        fname = f"page_{i:03d}.pdf"
        if rename_files and daire_id:
            fname = f"{daire_id}.pdf"

        out_pages.append((fname, buf.getvalue()))

    return out_pages

# -----------------------------------------------------------------------------
# MANAS PDF Parser (IsÄ±tma / SÄ±cak Su / Su / Toplam)
# -----------------------------------------------------------------------------
def parse_manas_pdf_totals(pdf_bytes: bytes) -> Dict[str, Dict[str, float]]:
    reader = PdfReader(io.BytesIO(pdf_bytes))
    result: Dict[str, Dict[str, float]] = {}

    re_daire_norms = [
        re.compile(r"DAIRE\s*NO[^A-Z0-9]{0,15}([A-Z]\d)[^0-9]{0,20}(\d{1,4})"),
        re.compile(r"([A-Z]\d)[^\d\n\r]{0,30}DAIRE[^0-9]{0,10}(\d{1,4})"),
    ]
    re_daire_raws = [
        re.compile(r"DA[Ä°I]RE\s*NO[^A-Z0-9]{0,15}([A-Z]\d)[^0-9]{0,20}(\d{1,4})"),
        re.compile(r"([A-Z]\d)[^\d\n\r]{0,30}DA[Ä°I]RE[^0-9]{0,10}(\d{1,4})"),
    ]
    re_odenecek = re.compile(r"(?:Ã–DENECEK|ODENECEK)\s*TUTAR[^0-9]{0,10}([0-9\.\,]+)", re.IGNORECASE)
    re_toplam   = re.compile(r"TOPLAM\s+TUTAR[^0-9]{0,10}([0-9\.\,]+)", re.IGNORECASE)

    def find_daire_id(raw_text: str) -> Optional[str]:
        norm = _normalize_tr(raw_text)
        for rx in re_daire_norms:
            m = rx.search(norm)
            if m:
                return f"{m.group(1).upper()}-{_pad3_digits(m.group(2))}"
        for rx in re_daire_raws:
            m = rx.search(raw_text)
            if m:
                return f"{m.group(1).upper()}-{_pad3_digits(m.group(2))}"
        return None

    def grab_section_amount(norm_text: str, header_word: str) -> float:
        idx = norm_text.find(header_word)
        if idx == -1:
            return 0.0
        tail = norm_text[idx: idx + 2500]
        m = re_odenecek.search(tail)
        return _to_float_tr(m.group(1)) if m else 0.0

    for pi, page in enumerate(reader.pages):
        raw = page.extract_text() or ""
        norm = _normalize_tr(raw)

        did = find_daire_id(raw)
        if not did:
            if pi == 0:
                st.info("âš ï¸ Daire No satÄ±rÄ± bulunamadÄ±. Ä°lk sayfanÄ±n normalize iÃ§eriÄŸinin bir kÄ±smÄ±:")
                st.code(norm[:800])
            continue

        isitma = grab_section_amount(norm, "ISITMA")
        sicak  = grab_section_amount(norm, "SICAK SU")

        # SU baÅŸlÄ±ÄŸÄ± SICAK SU ile karÄ±ÅŸmasÄ±n:
        su = 0.0
        idx_sicak = norm.find("SICAK SU")
        search_base = norm[idx_sicak + 8:] if idx_sicak != -1 else norm
        idx_su = search_base.find("\nSU")
        if idx_su == -1:
            idx_su = search_base.find(" SU ")
        if idx_su != -1:
            tail_su = search_base[idx_su: idx_su + 2000]
            m_su = re_odenecek.search(tail_su)
            if m_su:
                su = _to_float_tr(m_su.group(1))
        if su == 0.0:
            su = grab_section_amount(norm, "\nSU")

        mt = re_toplam.search(norm)
        toplam = _to_float_tr(mt.group(1)) if mt else (isitma + sicak + su)

        result[did] = {"isitma": isitma, "sicak": sicak, "su": su, "toplam": toplam}

    return result

# -----------------------------------------------------------------------------
# Apsiyon Excel YardÄ±mcÄ±larÄ±
# -----------------------------------------------------------------------------
def _norm_cols(s: str) -> str:
    return (str(s).strip().lower()
            .replace("\n"," ").replace("\r"," ")
            .replace(".","").replace("_"," ").replace("-"," "))

def _pad3_aps(x) -> str:
    try:
        n = int(str(x).strip());  return f"{n:03d}"
    except:
        s = str(x).strip()
        nums = "".join([ch for ch in s if ch.isdigit()])
        return f"{int(nums):03d}" if nums else s

def _find_header_row(df_raw: pd.DataFrame) -> Optional[int]:
    limit = min(15, len(df_raw))
    for i in range(limit):
        cells = [_norm_cols(c) for c in list(df_raw.iloc[i].values)]
        row_text = " | ".join(cells)
        if ("blok" in row_text) and (("daire no" in row_text) or ("daire" in row_text)):
            return i
    return None

def _rename_apsiyon_cols(df: pd.DataFrame) -> pd.DataFrame:
    mapping = {}
    for c in df.columns:
        nc = _norm_cols(c)
        if "blok" == nc:
            mapping[c] = "Blok"
        elif ("daire no" == nc) or (nc == "daire") or ("daire  no" == nc) or ("daireno" == nc):
            mapping[c] = "Daire No"
        elif "gider1 tutarÄ±" in nc or "gider 1 tutarÄ±" in nc or "gider1 tutari" in nc:
            mapping[c] = "Gider1 TutarÄ±"
        elif "gider1 aÃ§Ä±klamasÄ±" in nc or "gider 1 aciklamasi" in nc or "gider1 aciklamasi" in nc:
            mapping[c] = "Gider1 AÃ§Ä±klamasÄ±"
        elif "gider2 tutarÄ±" in nc or "gider 2 tutarÄ±" in nc or "gider2 tutari" in nc:
            mapping[c] = "Gider2 TutarÄ±"
        elif "gider2 aÃ§Ä±klamasÄ±" in nc or "gider 2 aciklamasi" in nc or "gider2 aciklamasi" in nc:
            mapping[c] = "Gider2 AÃ§Ä±klamasÄ±"
        elif "gider3 tutarÄ±" in nc or "gider 3 tutarÄ±" in nc or "gider3 tutari" in nc:
            mapping[c] = "Gider3 TutarÄ±"
        elif "gider3 aÃ§Ä±klamasÄ±" in nc or "gider 3 aciklamasi" in nc or "gider3 aciklamasi" in nc:
            mapping[c] = "Gider3 AÃ§Ä±klamasÄ±"
    df2 = df.rename(columns=mapping)
    for col in ["Gider1 TutarÄ±","Gider1 AÃ§Ä±klamasÄ±","Gider2 TutarÄ±","Gider2 AÃ§Ä±klamasÄ±","Gider3 TutarÄ±","Gider3 AÃ§Ä±klamasÄ±"]:
        if col not in df2.columns:
            df2[col] = None
    return df2

def load_apsiyon_template(excel_bytes: bytes) -> pd.DataFrame:
    from io import BytesIO
    raw = pd.read_excel(BytesIO(excel_bytes), header=None, engine="openpyxl")
    hdr = _find_header_row(raw)
    if hdr is None:
        df = pd.read_excel(BytesIO(excel_bytes), engine="openpyxl")
    else:
        df = pd.read_excel(BytesIO(excel_bytes), header=hdr, engine="openpyxl")
    df = _rename_apsiyon_cols(df)
    if ("Blok" not in df.columns) or ("Daire No" not in df.columns):
        st.error("Excelâ€™de 'Blok' ve 'Daire No' sÃ¼tunlarÄ± bulunamadÄ±.")
        st.dataframe(df.head(10))
        raise ValueError("Apsiyon ÅŸablonunda 'Blok' / 'Daire No' baÅŸlÄ±klarÄ± tespit edilemedi.")
    return df

def fill_expenses_to_apsiyon(
    df_in: pd.DataFrame,
    totals: dict,
    mode: str,
    exp1: str,
    exp2: str,
    exp3: str,
) -> pd.DataFrame:
    df = df_in.copy()
    def make_did(blok, dno) -> str:
        b = str(blok).strip().upper()
        d = _pad3_aps(dno)
        return f"{b}-{d}"
    g1t, g1a = "Gider1 TutarÄ±", "Gider1 AÃ§Ä±klamasÄ±"
    g2t, g2a = "Gider2 TutarÄ±", "Gider2 AÃ§Ä±klamasÄ±"
    g3t, g3a = "Gider3 TutarÄ±", "Gider3 AÃ§Ä±klamasÄ±"
    for idx, row in df.iterrows():
        did = make_did(row.get("Blok", ""), row.get("Daire No", ""))
        if did in totals:
            t = totals[did]
            if mode.startswith("SeÃ§enek 1"):
                df.at[idx, g1t] = t.get("sicak", 0.0); df.at[idx, g1a] = exp1 or ""
                df.at[idx, g2t] = t.get("su", 0.0);    df.at[idx, g2a] = exp2 or ""
                df.at[idx, g3t] = t.get("isitma", 0.0);df.at[idx, g3a] = exp3 or ""
            else:
                df.at[idx, g1t] = t.get("toplam", 0.0); df.at[idx, g1a] = exp1 or ""
                df.at[idx, g2t] = None; df.at[idx, g2a] = None
                df.at[idx, g3t] = None; df.at[idx, g3a] = None
    return df

def export_excel_bytes(df: pd.DataFrame, filename: str = "Apsiyon_Doldurulmus.xlsx") -> bytes:
    from io import BytesIO
    bio = BytesIO()
    with pd.ExcelWriter(bio, engine="openpyxl") as writer:
        df.to_excel(writer, index=False, sheet_name="Sheet1")
    return bio.getvalue()

# -----------------------------------------------------------------------------
# Rehber Okuyucu (WhatsApp iÃ§in) â€” Esnek: Apsiyon veya Basit CSV ÅŸemasÄ±
# -----------------------------------------------------------------------------
def _norm_rehber(s: str) -> str:
    return (str(s).strip().lower()
            .replace("\n"," ").replace("\r"," ")
            .replace(".","").replace("_"," ").replace("-"," "))

def _find_header_row_contacts(df_raw: pd.DataFrame, search_rows: int = 50) -> Optional[int]:
    """
    'Blok' + ('Daire'/'Daire No') + ('Telefon'/'Tel'/'GSM'/'Cep') birlikte gÃ¶rÃ¼nen satÄ±rÄ± baÅŸlÄ±k kabul eder.
    Ama basit CSV ÅŸemasÄ±nÄ± (phone/name/daire_id) da destekleyeceÄŸiz; o durumda 0 dÃ¶ner.
    """
    limit = min(search_rows, len(df_raw))
    for i in range(limit):
        cells = [_norm_rehber(c) for c in list(df_raw.iloc[i].values)]
        row_text = " | ".join(cells)
        has_blok  = "blok" in row_text or "block" in row_text
        has_daire = ("daire no" in row_text) or ("daire  no" in row_text) or ("daire" in row_text) \
                    or ("daireno" in row_text) or ("apartment" in row_text) or ("flat" in row_text)
        has_tel   = ("telefon" in row_text) or ("tel" in row_text) or ("gsm" in row_text) or ("cep" in row_text) \
                    or ("telefon no" in row_text) or ("phone" in row_text) or ("mobile" in row_text)
        if has_blok and has_daire and has_tel:
            return i
    # Esnek davran: bulamazsa 0 kabul et (Ã§oÄŸu CSV zaten ilk satÄ±r baÅŸlÄ±k)
    return 0

def _map_contact_columns(df: pd.DataFrame) -> pd.DataFrame:
    """
    Hem Apsiyon baÅŸlÄ±klarÄ±nÄ± hem de basit CSV baÅŸlÄ±klarÄ±nÄ± destekler.
    Hedef final kolonlar: Blok, Daire No, Ad Soyad / Unvan (ops), Telefon
    AyrÄ±ca daire_id varsa parÃ§alar.
    """
    # Orijinal kolon adlarÄ±
    original_cols = list(df.columns)

    # Ã–nce normalize edilmiÅŸ bir isim haritasÄ± oluÅŸtur
    norm_map = {_norm_rehber(c): c for c in original_cols}

    # Basit CSV ÅŸemasÄ± mÄ±? (phone + daire_id)
    has_phone    = any(k in norm_map for k in ["phone","mobile","telefon","tel","gsm","cep","telefon no"])
    has_daire_id = any(k in norm_map for k in ["daire id","daireid","daireid ","daire_id"])
    if has_phone and has_daire_id:
        c_phone    = norm_map.get("phone") or norm_map.get("mobile") or norm_map.get("telefon") \
                     or norm_map.get("tel") or norm_map.get("gsm") or norm_map.get("cep") or norm_map.get("telefon no")
        c_daire_id = norm_map.get("daire id") or norm_map.get("daireid") or norm_map.get("daireid ") or norm_map.get("daire_id")
        c_name     = norm_map.get("name") or norm_map.get("ad soyad") or norm_map.get("ad soyad  unvan") \
                     or norm_map.get("ad soyad/unvan") or norm_map.get("unvan")

        # Yeni DataFrameâ€™i oluÅŸtur
        tmp = pd.DataFrame()
        tmp["Telefon"] = df[c_phone].astype(str)
        tmp["Ad Soyad / Unvan"] = df[c_name].astype(str) if c_name else None
        tmp["DaireID"] = df[c_daire_id].astype(str)

        # DaireID â†’ Blok ve Daire No Ã§Ä±kar
        def _split_did(val: str) -> Tuple[str,str]:
            s = str(val).strip()
            m = (re.search(r"([A-Za-z]\d)\s*[-_ ]\s*(\d{1,3})", s)
                 or re.search(r"([A-Za-z]\d).*?(\d{3})", s)
                 or re.search(r"([A-Za-z]\d)\s+(\d{1,3})", s))
            if not m:
                return "", ""
            blok = m.group(1).upper()
            try:
                dno = f"{int(m.group(2)):03d}"
            except:
                dno = str(m.group(2)).zfill(3)
            return blok, dno

        tmp["Blok"], tmp["Daire No"] = zip(*tmp["DaireID"].map(_split_did))
        # Telefonu normalize et
        def _quick_norm_phone(x: str) -> str:
            s = re.sub(r"[^\d+]", "", str(x))
            if s.startswith("+"):                return s
            if re.fullmatch(r"05\d{9}", s):      return "+90" + s[1:]
            if re.fullmatch(r"5\d{9}", s):       return "+90" + s
            if re.fullmatch(r"0\d{10,11}", s):   return "+90" + s[1:]
            if re.fullmatch(r"90\d{10}", s):     return "+" + s
            return s
        tmp["Telefon"] = tmp["Telefon"].apply(_quick_norm_phone)

        # Eksik olanlarÄ± kontrol edip final dÃ¶ndÃ¼r
        if "Ad Soyad / Unvan" not in tmp.columns:
            tmp["Ad Soyad / Unvan"] = None
        tmp["Blok"] = tmp["Blok"].astype(str).str.upper().str.strip()
        tmp["Daire No"] = tmp["Daire No"].astype(str).str.replace(r"\D","", regex=True).str.zfill(3)
        tmp["DaireID"] = tmp["Blok"] + "-" + tmp["Daire No"]
        return tmp[["Blok","Daire No","Ad Soyad / Unvan","Telefon","DaireID"]]

    # Apsiyon ÅŸemasÄ± (TR/EN Ã§eÅŸitleri) â€” esnek eÅŸleme
    mapping = {}
    for c in original_cols:
        nc = _norm_rehber(c)
        if nc in ("blok","blok adi","blok adÄ±","blokadi","blok ad","blokad","block"):
            mapping[c] = "Blok"
        elif nc in ("daire no","daire  no","daireno","daire","apartment","flat","apt no","apartment no","unit","unit no"):
            mapping[c] = "Daire No"
        elif ("ad soyad / unvan" in nc) or ("ad soyad/unvan" in nc) or ("ad soyad" in nc) or ("unvan" in nc) or (nc == "name") or ("full name" in nc):
            mapping[c] = "Ad Soyad / Unvan"
        elif (nc in ("telefon","tel","cep","gsm","telefon no","tel no","telefon numarasi","telefon numarasÄ±","phone","mobile")) or ("telefon no" in nc):
            mapping[c] = "Telefon"
        elif nc in ("daire id","daireid","daire id ","daire_id"):
            mapping[c] = "DaireID"

    df2 = df.rename(columns=mapping)

    # EÄŸer DaireID var ve Blok/Daire No yoksa parÃ§ala
    if "DaireID" in df2.columns and (("Blok" not in df2.columns) or ("Daire No" not in df2.columns)):
        def _split_did2(val: str) -> Tuple[str,str]:
            s = str(val).strip()
            m = (re.search(r"([A-Za-z]\d)\s*[-_ ]\s*(\d{1,3})", s)
                 or re.search(r"([A-Za-z]\d).*?(\d{3})", s)
                 or re.search(r"([A-Za-z]\d)\s+(\d{1,3})", s))
            if not m:
                return "", ""
            blok = m.group(1).upper()
            try:
                dno = f"{int(m.group(2)):03d}"
            except:
                dno = str(m.group(2)).zfill(3)
            return blok, dno
        blk, dno = zip(*df2["DaireID"].map(_split_did2))
        df2["Blok"] = df2.get("Blok", pd.Series(blk)).fillna(blk)
        df2["Daire No"] = df2.get("Daire No", pd.Series(dno)).fillna(dno)

    # Zorunlu kolonlar
    for need in ["Blok","Daire No","Telefon"]:
        if need not in df2.columns:
            # Basit hata gÃ¶sterimi iÃ§in aynÄ± uyarÄ± metnini kullanalÄ±m
            cols_map_debug = {c: _norm_rehber(c) for c in df.columns}
            st.error(f"Rehberde zorunlu kolon(lar) eksik: Blok, Daire No, Telefon")
            st.write("AlgÄ±lanan kolonlar (normalize):", cols_map_debug)
            raise ValueError("Apsiyon rehber baÅŸlÄ±k eÅŸlemesi yapÄ±lamadÄ±.")

    # Temizlik
    def _pad3_for_merge(x) -> str:
        digits = "".join(ch for ch in str(x or "") if str(x))
        digits = "".join(ch for ch in str(x or "") if ch.isdigit())
        return digits.zfill(3) if digits else ""

    def _quick_norm_phone(x: str) -> str:
        s = re.sub(r"[^\d+]", "", str(x))
        if s.startswith("+"):                return s
        if re.fullmatch(r"05\d{9}", s):      return "+90" + s[1:]
        if re.fullmatch(r"5\d{9}", s):       return "+90" + s
        if re.fullmatch(r"0\d{10,11}", s):   return "+90" + s[1:]
        if re.fullmatch(r"90\d{10}", s):     return "+" + s
        return s

    if "Ad Soyad / Unvan" not in df2.columns:
        df2["Ad Soyad / Unvan"] = None

    df2["Blok"] = df2["Blok"].astype(str).str.upper().str.strip()
    df2["Daire No"] = df2["Daire No"].apply(_pad3_for_merge)
    df2["Telefon"] = df2["Telefon"].apply(_quick_norm_phone)
    df2["DaireID"] = df2["Blok"] + "-" + df2["Daire No"]

    return df2[["Blok","Daire No","Ad Soyad / Unvan","Telefon","DaireID"]]


def load_contacts_any(file_bytes: bytes, filename: str) -> pd.DataFrame:
    """
    - Apsiyon ham Excel/CSV (Blok, Daire No, Telefon â€¦)
    - Basit CSV (phone, name, daire_id, [file_name])
    ÅemalarÄ±nÄ±n her ikisini de kabul eder.
    """
    from io import BytesIO

    # 1) Ham oku (header=None) ve mantÄ±klÄ± baÅŸlÄ±k satÄ±rÄ± tespit et
    if filename.lower().endswith(".csv"):
        raw = pd.read_csv(BytesIO(file_bytes), header=None, dtype=str)
    else:
        raw = pd.read_excel(BytesIO(file_bytes), header=None, dtype=str, engine="openpyxl")

    hdr = _find_header_row_contacts(raw, search_rows=50)

    # 2) BaÅŸlÄ±kla tekrar oku
    if filename.lower().endswith(".csv"):
        df = pd.read_csv(BytesIO(file_bytes), header=hdr, dtype=str)
    else:
        df = pd.read_excel(BytesIO(file_bytes), header=hdr, dtype=str, engine="openpyxl")

    # 3) 'Unnamed' kolon isimlerini bir Ã¼st satÄ±rdan dÃ¼zelt (Apsiyon ham dosyalarda sÄ±k gÃ¶rÃ¼lÃ¼r)
    if hdr > 0:
        upper = raw.iloc[hdr-1]
        new_cols = []
        for i, c in enumerate(df.columns):
            name = str(c)
            if name.lower().startswith("unnamed"):
                alt = upper[i] if i < len(upper) else None
                if pd.notna(alt) and str(alt).strip():
                    name = str(alt)
                else:
                    name = f"Kolon_{i+1}"
            new_cols.append(name)
        df.columns = new_cols

    # 4) Tamamen boÅŸ kolonlarÄ± at
    df = df.dropna(axis=1, how="all")

    # 5) Esnek kolon eÅŸlemesi ve temiz DataFrame
    out = _map_contact_columns(df)
    return out

# -----------------------------------------------------------------------------
# Google Drive â€” Servis HesabÄ± ile klasÃ¶rden PDF listeleme + tekil link Ã¼retme
# -----------------------------------------------------------------------------
DEFAULT_DRIVE_FOLDER_ID = "1P8CZXb0G0RcNIe89CIyDASCborzmgSYF"  # senin verdiÄŸin klasÃ¶r

def _drive_available() -> bool:
    try:
        import googleapiclient.discovery  # noqa
        from google.oauth2 import service_account  # noqa
        return True
    except Exception:
        return False

def get_drive_service(json_key_path: str):
    from google.oauth2 import service_account
    from googleapiclient.discovery import build
    scopes = ["https://www.googleapis.com/auth/drive"]
    creds = service_account.Credentials.from_service_account_file(json_key_path, scopes=scopes)
    return build("drive", "v3", credentials=creds, cache_discovery=False)

def list_pdfs_in_folder(service, folder_id: str) -> list[dict]:
    q = f"'{folder_id}' in parents and mimeType='application/pdf' and trashed=false"
    fields = "files(id,name,webViewLink,webContentLink),nextPageToken"
    files = []
    page_token = None
    while True:
        resp = service.files().list(q=q, fields=fields, pageToken=page_token).execute()
        items = resp.get("files", [])
        files.extend(items)
        page_token = resp.get("nextPageToken")
        if not page_token:
            break
    return files

def ensure_anyone_viewer_and_get_link(service, file_id: str) -> str:
    """DosyayÄ± linke sahip herkese 'gÃ¶rÃ¼ntÃ¼leyici' yapar ve webViewLink dÃ¶ner."""
    # link permissions â€” errors ignore if already exists
    try:
        service.permissions().create(
            fileId=file_id,
            body={"type": "anyone", "role": "reader"},
            fields="id"
        ).execute()
    except Exception:
        pass
    file_meta = service.files().get(fileId=file_id, fields="webViewLink").execute()
    return file_meta.get("webViewLink", f"https://drive.google.com/file/d/{file_id}/view")

def extract_daire_from_filename(name: str) -> Optional[str]:
    """
    A1-1.pdf, A1-001.pdf, A1_12.pdf, A1 12.pdf, A1.012.pdf gibi varyantlardan 'A1-012' Ã¼retir.
    """
    base = name.rsplit("/",1)[-1].rsplit("\\",1)[-1]
    base = re.sub(r"\.pdf$", "", base, flags=re.IGNORECASE)
    m = (re.search(r"([A-Za-z]\d)\s*[-_ .]\s*(\d{1,3})", base)
         or re.search(r"([A-Za-z]\d)\s+(\d{1,3})", base)
         or re.search(r"([A-Za-z]\d).*?(\d{3})", base))
    if not m:
        return None
    blok = m.group(1).upper()
    try:
        dno = f"{int(m.group(2)):03d}"
    except:
        dno = m.group(2).zfill(3)
    return f"{blok}-{dno}"

# -----------------------------------------------------------------------------
# UI â€” 3 Sekme
# -----------------------------------------------------------------------------
st.title("ğŸ§¾ Vadi Fatura â€” BÃ¶l & Alt YazÄ± & Apsiyon")

tab_a, tab_b, tab_c = st.tabs([
    "ğŸ“„ BÃ¶l & Alt YazÄ±",
    "ğŸ“Š Apsiyon Gider Doldurucu",
    "ğŸ“¤ WhatsApp GÃ¶nderim HazÄ±rlÄ±ÄŸÄ±"
])

# ---------------- TAB A: BÃ¶l & Alt YazÄ± ----------------
with tab_a:
    pdf_file = st.file_uploader("Fatura PDF dosyasÄ±nÄ± yÃ¼kle", type=["pdf"], key="pdf_a")

    if pdf_file:
        st.session_state["pdf_bytes"] = pdf_file.getvalue()

    st.subheader("Alt YazÄ± KaynaÄŸÄ±")
    t1, t2 = st.tabs(["âœï¸ Metin alanÄ±", "ğŸ“„ .docx yÃ¼kle (opsiyonel)"])

    default_text = (
        "SON Ã–DEME TARÄ°HÄ°     24.10.2025\n\n"
        "Manas paylaÅŸÄ±mlarÄ±nda oturumda olup (0) gelen dairelerin Ã¶nceki Ã¶dediÄŸi paylaÅŸÄ±m tutarlarÄ± baz alÄ±narak "
        "bedel yansÄ±tÄ±lmasÄ±; ayrÄ±ca Ä°SKÄ° su sayacÄ±nÄ±n okuduÄŸu harcama tutarÄ± ile site iÃ§erisindeki harcama tutarÄ± "
        "arasÄ±ndaki farkÄ±n Ä°SKÄ° faturasÄ±nÄ±n Ã¶denebilmesi iÃ§in 152 daireye eÅŸit olarak yansÄ±tÄ±lmasÄ± oya sunuldu. "
        "OybirliÄŸi ile kabul edildi.\n\n"
        "28.02.2017 TARÄ°HLÄ° TEMSÄ°LCÄ°LER OLAÄAN TOPLANTISINDA ALINAN KARARA Ä°STÄ°NADEN\n"
        "AÃ‡IKLAMA\n"
        "Ä°ski saatinden okunan m3 = 1.319  M3\n"
        "Manas okumasÄ± m3= 1.202,5 M3\n"
        "Ortak alan tÃ¼ketimler m3= 32  M3 \n"
        "AÃ§Ä±kta kalan:  84,5 m3     \n"
        "Su m3 fiyatÄ± 82,09   TL    84,5*82,9 = 7.005,05 TL / 152 = 46,08 TL."
    )

    with t1:
        footer_text = st.text_area("Alt yazÄ±", value=default_text, height=220, key="footer_text")

    with t2:
        if not HAS_DOCX:
            st.info("python-docx yÃ¼klÃ¼ deÄŸilse .docx modu devre dÄ±ÅŸÄ± olur.")
        docx_file = st.file_uploader(".docx yÃ¼kleyin (opsiyonel)", type=["docx"], key="docx_up")
        if docx_file and HAS_DOCX:
            try:
                d = docx.Document(docx_file)
                paragraphs = [p.text for p in d.paragraphs]
                docx_text = "\n".join(paragraphs).strip()
                if docx_text:
                    footer_text = docx_text
                    st.success("Alt yazÄ± .docx iÃ§eriÄŸinden alÄ±ndÄ±.")
            except Exception as e:
                st.error(f".docx okunamadÄ±: {e}")

    st.subheader("GÃ¶rÃ¼nÃ¼m AyarlarÄ±")
    c1, c2 = st.columns(2)
    with c1:
        font_size = st.slider("ğŸ…°ï¸ YazÄ± Boyutu", 9, 16, 11, key="fs")
        leading   = st.slider("â†•ï¸ SatÄ±r AralÄ±ÄŸÄ± (pt)", 12, 22, 14, key="lead")
    with c2:
        align     = st.radio("Hizalama", ["left", "center"], index=0, key="align", format_func=lambda x: "Sol" if x=="left" else "Orta")
        bottom_m  = st.slider("Alt Marj (pt)", 24, 100, 48, key="bm")
    box_h = st.slider("Alt YazÄ± AlanÄ± YÃ¼ksekliÄŸi (pt)", 100, 260, 180, key="bh")
    bold_rules = st.checkbox("BaÅŸlÄ±klarÄ± otomatik kalÄ±n yap (SON Ã–DEME, AÃ‡IKLAMA, ...)", value=True, key="boldrules")

    with st.expander("ğŸ·ï¸ Daire numarasÄ± etiketi & yeniden adlandÄ±rma (opsiyonel)", expanded=False):
        stamp_on = st.checkbox("Daire numarasÄ±nÄ± kÃ¶ÅŸeye yaz", value=False, key="stamp_on")
        label_tpl = st.text_input("Etiket ÅŸablonu", value="Daire: {daire_id}", key="label_tpl")
        c3, c4, c5 = st.columns(3)
        with c3:
            stamp_font_size = st.slider("Etiket punto", 10, 20, 13, key="stamp_fs")
        with c4:
            stamp_pos = st.selectbox("Konum", ["TR", "TL", "BR", "BL"], index=0, key="stamp_pos")
        with c5:
            stamp_bold = st.checkbox("KalÄ±n", value=True, key="stamp_bold")
        c6, c7 = st.columns(2)
        with c6:
            pad_x = st.slider("KÃ¶ÅŸe yatay boÅŸluk (px)", 0, 80, 20, step=2, key="pad_x")
        with c7:
            pad_y = st.slider("KÃ¶ÅŸe dikey boÅŸluk (px)", 0, 80, 20, step=2, key="pad_y")
        rename_files = st.checkbox("BÃ¶lÃ¼nmÃ¼ÅŸ dosya adÄ±nÄ± daireID.pdf yap", value=True, key="rename_files")

    st.subheader("Ä°ÅŸlem")
    mode = st.radio(
        "Ne yapmak istersiniz?",
        ["Sadece sayfalara bÃ¶l", "Sadece alt yazÄ± uygula (tek PDF)", "Alt yazÄ± uygula + sayfalara bÃ¶l (ZIP)"],
        index=2,
        key="mode"
    )
    go = st.button("ğŸš€ BaÅŸlat", key="go_a")

    if go:
        if not pdf_file:
            st.warning("LÃ¼tfen Ã¶nce bir PDF yÃ¼kleyin.")
            st.stop()

        src = pdf_file.read()

        if mode == "Sadece sayfalara bÃ¶l":
            pages = split_pdf(src)
            with io.BytesIO() as zbuf:
                with zipfile.ZipFile(zbuf, "w", zipfile.ZIP_DEFLATED) as z:
                    for name, data in pages:
                        z.writestr(name, data)
                st.download_button("ğŸ“¥ BÃ¶lÃ¼nmÃ¼ÅŸ sayfalar (ZIP)", zbuf.getvalue(), file_name="bolunmus_sayfalar.zip")

        elif mode == "Sadece alt yazÄ± uygula (tek PDF)":
            stamped = add_footer_to_pdf(
                src,
                footer_text=footer_text,
                font_size=font_size,
                leading=leading,
                align=align,
                bottom_margin=bottom_m,
                box_height=box_h,
                bold_rules=bold_rules,
            )
            st.download_button("ğŸ“¥ Alt yazÄ±lÄ± PDF", stamped, file_name="alt_yazili.pdf")

        else:
            footer_kwargs = dict(
                footer_text=footer_text,
                font_size=font_size,
                leading=leading,
                align=align,
                bottom_margin=bottom_m,
                box_height=box_h,
                bold_rules=bold_rules,
            )
            stamp_opts = dict(
                font_size=stamp_font_size,
                bold=stamp_bold,
                position=stamp_pos,
                pad_x=pad_x,
                pad_y=pad_y,
            )
            pages = add_footer_and_stamp_per_page(
                src_bytes=src,
                footer_kwargs=footer_kwargs,
                stamp_on=stamp_on,
                label_tpl=label_tpl,
                stamp_opts=stamp_opts,
                rename_files=rename_files,
            )
            with io.BytesIO() as zbuf:
                with zipfile.ZipFile(zbuf, "w", zipfile.ZIP_DEFLATED) as z:
                    for name, data in pages:
                        z.writestr(name, data)
                st.download_button("ğŸ“¥ Alt yazÄ±lÄ± & bÃ¶lÃ¼nmÃ¼ÅŸ (ZIP)", zbuf.getvalue(), file_name="alt_yazili_bolunmus.zip")

# ---------------- TAB B: Apsiyon Gider Doldurucu ----------------
with tab_b:
    st.subheader("ğŸ“Š Apsiyon Gider Doldurucu")
    apsiyon_file = st.file_uploader("Apsiyon 'boÅŸ ÅŸablon' Excel dosyasÄ±nÄ± yÃ¼kle (.xlsx)", type=["xlsx"], key="apsiyon_up")

    colM1, colM2 = st.columns(2)
    with colM1:
        aps_mode = st.radio(
            "Doldurma Åekli",
            ["SeÃ§enek 1 (G1=SÄ±cak Su, G2=Su, G3=IsÄ±tma)", "SeÃ§enek 2 (G1=Toplam, G2/G3 boÅŸ)"],
            index=0,
            key="aps_mode"
        )
    with colM2:
        exp1 = st.text_input("Gider1 AÃ§Ä±klamasÄ±", value="SÄ±cak Su", key="aps_exp1")
        exp2 = st.text_input("Gider2 AÃ§Ä±klamasÄ±", value="SoÄŸuk Su", key="aps_exp2")
        exp3 = st.text_input("Gider3 AÃ§Ä±klamasÄ±", value="IsÄ±tma", key="aps_exp3")

    go_fill = st.button("ğŸ“¥ PDFâ€™ten tutarlarÄ± Ã§ek ve Excelâ€™e yaz", key="go_fill")

    if go_fill:
        pdf_bytes = st.session_state.get("pdf_bytes")
        if not pdf_bytes:
            st.warning("Ã–nce A sekmesinde fatura PDFâ€™sini yÃ¼kleyin (aynÄ± PDF).")
            st.stop()
        if not apsiyon_file:
            st.warning("Apsiyon Excel ÅŸablonunu yÃ¼kleyin.")
            st.stop()

        totals_map = parse_manas_pdf_totals(pdf_bytes)
        if not totals_map:
            st.error("PDFâ€™ten tutar okunamadÄ±. (Daire baÅŸlÄ±klarÄ± veya tutarlar bulunamadÄ±)")
            st.stop()

        try:
            df_aps = load_apsiyon_template(apsiyon_file.read())
        except Exception as e:
            st.error(f"Excel okunamadÄ±: {e}")
            st.stop()

        df_out = fill_expenses_to_apsiyon(df_aps, totals_map, aps_mode, exp1, exp2, exp3)
        out_bytes = export_excel_bytes(df_out)
        st.success("Excel dolduruldu.")
        st.download_button(
            "ğŸ“¥ DoldurulmuÅŸ Apsiyon Excel",
            out_bytes,
            file_name="Apsiyon_Doldurulmus.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            key="dl_aps"
        )

# ---------------- TAB C: WhatsApp GÃ¶nderim HazÄ±rlÄ±ÄŸÄ± ----------------
with tab_c:
    st.markdown("""
    <div style='background-color:#25D366;padding:10px 16px;border-radius:10px;display:flex;align-items:center;gap:10px;color:white;margin-bottom:15px;'>
      <img src='https://upload.wikimedia.org/wikipedia/commons/6/6b/WhatsApp.svg' width='28'>
      <h3 style='margin:0;'>WhatsApp GÃ¶nderim HazÄ±rlÄ±ÄŸÄ±</h3>
    </div>
    """, unsafe_allow_html=True)

    wa_tab1, wa_tab2 = st.tabs([
        "ZIP + (opsiyonel) Base URL",
        "Google Drive klasÃ¶rÃ¼nden link Ã¼ret"
    ])

    # --- Yol 1: ZIP + Base URL (mevcut akÄ±ÅŸ) ---
    with wa_tab1:
        up1, up2 = st.columns([1,1], vertical_alignment="top")
        with up1:
            st.markdown("**AdÄ±m 1:** BÃ¶lÃ¼nmÃ¼ÅŸ PDFâ€™lerin olduÄŸu **ZIP**â€™i yÃ¼kle (dosya adlarÄ± `A1-001.pdf` gibi).")
            zip_up = st.file_uploader("BÃ¶lÃ¼nmÃ¼ÅŸ PDF ZIP", type=["zip"], key="wa_zip", label_visibility="collapsed")
        with up2:
            st.markdown("**AdÄ±m 2:** GÃ¼ncel **Rehber** dosyasÄ±nÄ± yÃ¼kle (Apsiyon ham Excel/CSV).")
            rehber_up = st.file_uploader("Rehber (XLSX/CSV)", type=["xlsx","csv"], key="wa_rehber", label_visibility="collapsed")

        with st.expander("ğŸ”— Opsiyonel link Ã¼retimi (base URL)", expanded=False):
            base_url = st.text_input("Base URL (Ã¶rn: https://cdn.site.com/faturalar/ )", value="", key="wa_base")

        ctop1, ctop2 = st.columns([1,3], vertical_alignment="center")
        with ctop1:
            go_btn = st.button("ğŸ“‘ EÅŸleÅŸtir ve CSV oluÅŸtur", use_container_width=True, key="wa_go")
        with ctop2:
            st.caption("Butona bastÄ±ktan sonra aÅŸaÄŸÄ±da Ã¶nizleme ve indirme butonu gÃ¶rÃ¼nÃ¼r.")

        if go_btn:
            if not zip_up:
                st.warning("Ã–nce ZIP yÃ¼kleyin."); st.stop()
            if not rehber_up:
                st.warning("Ã–nce Rehber dosyasÄ± yÃ¼kleyin."); st.stop()

            # ZIP â†’ PDF listesi + DaireID Ã§Ä±kar
            try:
                zf = zipfile.ZipFile(zip_up)
                pdf_rows = []
                for info in zf.infolist():
                    if info.is_dir() or (not info.filename.lower().endswith(".pdf")):
                        continue
                    base = info.filename.rsplit("/",1)[-1].rsplit("\\",1)[-1]
                    m = (re.search(r"([A-Za-z]\d)\s*[-_]\s*(\d{1,3})", base)
                         or re.search(r"([A-Za-z]\d)\s+(\d{1,3})", base)
                         or re.search(r"([A-Za-z]\d).*?(\d{3})", base))
                    daire_id = None
                    if m:
                        try:
                            daire_id = f"{m.group(1).upper()}-{int(m.group(2)):03d}"
                        except:
                            daire_id = f"{m.group(1).upper()}-{m.group(2)}"
                    pdf_rows.append({"file_name": base, "DaireID": daire_id})
                pdf_df = pd.DataFrame(pdf_rows)
            except Exception as e:
                st.error(f"ZIP okunamadÄ±: {e}"); st.stop()

            if pdf_df.empty:
                st.error("ZIPâ€™te PDF bulunamadÄ±."); st.stop()

            # Rehber oku
            try:
                rehber_df = load_contacts_any(rehber_up.read(), rehber_up.name)
            except Exception as e:
                st.error(f"Rehber okunamadÄ± / eÅŸlenemedi: {e}"); st.stop()

            # EÅŸleÅŸtirme
            merged = pdf_df.merge(rehber_df[["DaireID","Telefon","Ad Soyad / Unvan"]], on="DaireID", how="left")
            merged["file_url"] = merged["file_name"].apply(
                lambda fn: (base_url.rstrip("/") + "/" + fn) if base_url and base_url.strip() else ""
            )

            a1, a2, a3 = st.columns(3)
            with a1: st.metric("Toplam kayÄ±t", len(merged))
            with a2: st.metric("DaireID bulunamadÄ±", int(merged["DaireID"].isna().sum()))
            with a3: st.metric("Telefon eksik", int((merged["Telefon"].isna() | (merged["Telefon"]=="")).sum()))

            st.markdown("**EÅŸleÅŸtirme Ã–nizleme**")
            st.dataframe(merged.rename(columns={"Telefon":"phone", "Ad Soyad / Unvan":"name"}),
                         use_container_width=True, height=600)

            out_csv = merged.rename(columns={
                "Telefon": "phone",
                "Ad Soyad / Unvan": "name",
                "DaireID": "daire_id",
                "file_name": "file_name",
                "file_url": "file_url",
            })[["phone","name","daire_id","file_name","file_url"]]
            b_csv = out_csv.to_csv(index=False).encode("utf-8-sig")
            st.download_button("ğŸ“¥ WhatsApp_Recipients.csv (UTF-8, BOM)", b_csv,
                               file_name="WhatsApp_Recipients.csv", mime="text/csv", use_container_width=True, key="dl_csv")

    # --- Yol 2: Google Drive klasÃ¶rÃ¼nden PDF listele + tekil link Ã¼ret ---
with wa_tab2:
    st.markdown("**Bu yÃ¶ntemde ZIP gerekmez.** PDFâ€™leri Google Driveâ€™daki klasÃ¶re koyman yeterli.")
    if not _GDRIVE_OK:
        st.error("Google Drive kÃ¼tÃ¼phaneleri yÃ¼klÃ¼ deÄŸil. Terminalde ÅŸunu kur:\n\npip install google-api-python-client google-auth google-auth-oauthlib")
    else:
        # JSON dosya yolu GÄ°TTÄ°. Secrets kullanÄ±yoruz.
        folder_id = st.text_input(
            "Drive Folder ID",
            value=DEFAULT_DRIVE_FOLDER_ID,
            help="KlasÃ¶r ID: 1P8CZXb0G0RcNIe89CIyDASCborzmgSYF"
        )

        # Rehber yÃ¼kleme (Apsiyon ham dosyasÄ±)
        rehber_up2 = st.file_uploader(
            "Rehber (XLSX/CSV) â€” Apsiyon ham dosya",
            type=["xlsx","csv"], key="wa_rehber2"
        )

        link_mode = st.radio(
            "Link tipi",
            ["DoÄŸrudan indirme (Ã¶nerilir)", "GÃ¶rÃ¼ntÃ¼leme linki (Drive gÃ¶rÃ¼nÃ¼mÃ¼)"],
            horizontal=True
        )

        drive_go = st.button("ğŸ—‚ï¸ Driveâ€™dan PDFâ€™leri Ã§ek, eÅŸleÅŸtir ve CSV Ã¼ret", use_container_width=True)

        if drive_go:
            if not folder_id.strip():
                st.error("Folder ID boÅŸ olamaz."); st.stop()
            if not rehber_up2:
                st.error("Rehber dosyasÄ± yÃ¼kleyin."); st.stop()

            # 1) Drive servisine baÄŸlan (Secrets)
            try:
                service = get_drive_service_from_secrets()
            except Exception as e:
                st.error(f"Drive servisine baÄŸlanÄ±lamadÄ±: {e}")
                st.stop()

            # 2) KlasÃ¶rdeki PDF'leri Ã§ek
            try:
                gfiles = list_pdfs_in_folder(service, folder_id.strip())
            except Exception as e:
                st.error(f"KlasÃ¶r listelenemedi: {e}")
                st.stop()

            if not gfiles:
                st.warning("KlasÃ¶rde PDF bulunamadÄ±."); st.stop()

            # 3) PDF adlarÄ±ndan DaireID tahmini (A1-001.pdf gibi)
            import re, pandas as pd
            pdf_rows = []
            for f in gfiles:
                base = f.get("name","")
                m = (re.search(r"([A-Za-z]\d)\s*[-_]\s*(\d{1,3})", base)
                     or re.search(r"([A-Za-z]\d)\s+(\d{1,3})", base)
                     or re.search(r"([A-Za-z]\d).*?(\d{3})", base))
                daire_id = None
                if m:
                    try:
                        daire_id = f"{m.group(1).upper()}-{int(m.group(2)):03d}"
                    except:
                        daire_id = f"{m.group(1).upper()}-{m.group(2)}"
                pdf_rows.append({"file_name": base, "DaireID": daire_id, "file_id": f["id"]})
            pdf_df = pd.DataFrame(pdf_rows)

            # 4) Rehberi oku
            try:
                rehber_df = load_contacts_any(rehber_up2.read(), rehber_up2.name)
            except Exception as e:
                st.error(f"Rehber okunamadÄ± / eÅŸlenemedi: {e}"); st.stop()

            # 5) EÅŸleÅŸtir
            merged = pdf_df.merge(
                rehber_df[["DaireID", "Telefon", "Ad Soyad / Unvan"]],
                on="DaireID",
                how="left"
            )

            # 6) DosyalarÄ± "linke sahip olan gÃ¶rÃ¼ntÃ¼leyebilir" yap + link Ã¼ret
            # (sadece dosya bazÄ±nda; klasÃ¶r listing aÃ§Ä±lmaz)
            link_kind = "download" if link_mode.startswith("DoÄŸrudan") else "view"

            st.write("ğŸ”“ Dosyalar paylaÅŸÄ±ma aÃ§Ä±lÄ±yor ve linkler oluÅŸturuluyor (dosya bazÄ±nda)...")
            for i, row in merged.iterrows():
                fid = row.get("file_id")
                if not fid:
                    continue
                try:
                    ensure_anyone_with_link_permission(service, fid)
                except Exception:
                    pass
                merged.at[i, "file_url"] = build_direct_file_link(fid, link_kind)

            # 7) Ã–nizleme + CSV
            a1, a2, a3 = st.columns(3)
            with a1: st.metric("Toplam kayÄ±t", len(merged))
            with a2: st.metric("DaireID bulunamadÄ±", int(merged["DaireID"].isna().sum()))
            with a3: st.metric("Telefon eksik", int((merged["Telefon"].isna() | (merged["Telefon"]=="")).sum()))

            st.markdown("**EÅŸleÅŸtirme Ã–nizleme**")
            st.dataframe(
                merged.rename(columns={"Telefon":"phone", "Ad Soyad / Unvan":"name"}),
                use_container_width=True, height=600
            )

            out_csv = merged.rename(columns={
                "Telefon": "phone",
                "Ad Soyad / Unvan": "name",
                "DaireID": "daire_id",
                "file_name": "file_name",
                "file_url": "file_url",
            })[["phone","name","daire_id","file_name","file_url"]]
            b_csv = out_csv.to_csv(index=False).encode("utf-8-sig")
            st.download_button(
                "ğŸ“¥ WhatsApp_Recipients.csv (Drive linkli)",
                b_csv,
                file_name="WhatsApp_Recipients.csv",
                mime="text/csv",
                use_container_width=True
            )

            with st.expander("ğŸ“¨ Ã–rnek mesaj gÃ¶vdesi", expanded=False):
                st.code(
                    "Merhaba {name},\n"
                    "{daire_id} numaralÄ± dairenizin aylÄ±k bildirimi hazÄ±rdÄ±r.\n"
                    "DosyayÄ± butondan gÃ¶rÃ¼ntÃ¼leyebilirsiniz.\n",
                    language="text"
                )
# ---------------- TAB W: WhatsApp GÃ¶nder (Cloud API) ----------------
with tab_w:
    st.markdown("### ğŸ“² WhatsApp GÃ¶nder (Meta Cloud API)")

    st.info("Ä°lk mesajÄ± **ÅŸablon** ile baÅŸlatmalÄ±sÄ±n. SonrasÄ±nda 24 saat iÃ§inde serbest metin / belge gÃ¶nderebilirsin.")

    colK1, colK2 = st.columns(2)
    with colK1:
        csv_up = st.file_uploader("WhatsApp_Recipients.csv yÃ¼kle", type=["csv"], key="wa_send_csv")
    with colK2:
        preview_btn = st.button("Ã–nizle", use_container_width=True, key="wa_preview")

    # API Kimlikleri (secrets varsa otomatik doldur)
    st.markdown("#### Cloud API AyarlarÄ±")
    default_token = st.secrets.get("whatsapp", {}).get("token", "")
    default_phone_id = st.secrets.get("whatsapp", {}).get("phone_number_id", "")
    colA1, colA2 = st.columns(2)
    with colA1:
        wa_token = st.text_input("Access Token", value=default_token, type="password", help="Meta for Developers â†’ WhatsApp â†’ System User token (mÃ¼mkÃ¼nse kalÄ±cÄ±).")
    with colA2:
        phone_number_id = st.text_input("Phone Number ID", value=default_phone_id, help="WABA iÃ§indeki WhatsApp numaranÄ±zÄ±n IDâ€™si")

    st.markdown("#### Åablonla BaÅŸlat (zorunlu ilk mesaj)")
    colT1, colT2, colT3 = st.columns(3)
    with colT1:
        template_name = st.text_input("Template adÄ±", value="fatura_bildirimi")  # Ã–rn: fatura_bildirimi
    with colT2:
        template_lang = st.text_input("Dil (BCP-47)", value="tr")  # tr, tr_TR gibi
    with colT3:
        header_document = st.checkbox("Åablon header'Ä± belge (document) kullansÄ±n", value=False,
                                      help="Åablonunuz 'HEADER: DOCUMENT' iÃ§eriyorsa iÅŸaretleyin. PDF linkini headerâ€™a koyacaÄŸÄ±z.")

    st.caption("Ã–rnek ÅŸablon gÃ¶vdesi (Meta'da oluÅŸturup onaylat):\n"
               "Merhaba {{1}},\n{{2}} dairenizin bildirimi hazÄ±rdÄ±r.\nDosya: {{3}}")

    st.markdown("#### 24 saat PENCERE AÃ‡ILDIKTAN SONRA opsiyonel mesaj")
    colF1, colF2 = st.columns(2)
    with colF1:
        send_followup_text = st.checkbox("ArdÄ±ndan serbest metin gÃ¶nder", value=False)
        followup_text = st.text_area("Serbest metin", value="Merhaba {name},\n{daire_id} dairenizin PDF bildirimi ektedir:\n{file_url}")
    with colF2:
        send_document = st.checkbox("ArdÄ±ndan PDF'yi belge (document) olarak gÃ¶nder", value=True,
                                    help="file_url doÄŸrudan indirilebilir/gÃ¶rÃ¼ntÃ¼lenebilir olmalÄ±.")

    go_send = st.button("ğŸš€ GÃ¶nderimi BaÅŸlat", use_container_width=True, key="wa_send")

    import time, requests
    import pandas as pd

    def _ok_number(s: str) -> str:
        s = str(s or "").strip()
        # "+90..." formatÄ± bekliyoruz; yoksa basit normalize
        s = s.replace(" ", "")
        if s.startswith("05") and len(s) == 11:
            return "+90" + s[1:]
        if s.startswith("5") and len(s) == 10:
            return "+90" + s
        if s.startswith("0") and len(s) in (10,11):
            return "+90" + s[1:]
        return s

    def send_template(access_token: str, phone_id: str, to: str, t_name: str, lang: str, name: str, daire_id: str, file_url: str, header_doc=False):
        url = f"https://graph.facebook.com/v20.0/{phone_id}/messages"
        headers = {"Authorization": f"Bearer {access_token}", "Content-Type": "application/json"}

        components = []
        # BODY vars
        components.append({
            "type": "body",
            "parameters": [
                {"type": "text", "text": name or ""},
                {"type": "text", "text": daire_id or ""},
                {"type": "text", "text": file_url or ""},
            ]
        })
        # HEADER document varsa (ÅŸablonunuzda HEADER: DOCUMENT tanÄ±mlÄ± olmalÄ±)
        if header_doc and file_url:
            components.insert(0, {
                "type": "header",
                "parameters": [
                    {"type": "document", "document": {"link": file_url, "filename": f"{daire_id or 'Dosya'}.pdf"}}
                ]
            })

        payload = {
            "messaging_product": "whatsapp",
            "to": to,
            "type": "template",
            "template": {
                "name": t_name,
                "language": {"code": lang},
                "components": components
            }
        }
        r = requests.post(url, headers=headers, json=payload, timeout=30)
        return r

    def send_text(access_token: str, phone_id: str, to: str, text: str):
        url = f"https://graph.facebook.com/v20.0/{phone_id}/messages"
        headers = {"Authorization": f"Bearer {access_token}", "Content-Type": "application/json"}
        payload = {
            "messaging_product": "whatsapp",
            "to": to,
            "type": "text",
            "text": {"preview_url": True, "body": text}
        }
        r = requests.post(url, headers=headers, json=payload, timeout=30)
        return r

    def send_document_msg(access_token: str, phone_id: str, to: str, file_url: str, caption: str):
        url = f"https://graph.facebook.com/v20.0/{phone_id}/messages"
        headers = {"Authorization": f"Bearer {access_token}", "Content-Type": "application/json"}
        payload = {
            "messaging_product": "whatsapp",
            "to": to,
            "type": "document",
            "document": {"link": file_url, "caption": caption}
        }
        r = requests.post(url, headers=headers, json=payload, timeout=30)
        return r

    if preview_btn and csv_up:
        df = pd.read_csv(csv_up, dtype=str).fillna("")
        st.dataframe(df.head(50), use_container_width=True)
        st.success(f"{len(df)} alÄ±cÄ± yÃ¼klendi.")

    if go_send:
        # doÄŸrulamalar
        if not csv_up:
            st.error("Ã–nce CSV yÃ¼kleyin."); st.stop()
        if not wa_token or not phone_number_id:
            st.error("Access Token ve Phone Number ID gerekir."); st.stop()
        df = pd.read_csv(csv_up, dtype=str).fillna("")
        if not {"phone","name","daire_id","file_url"}.issubset(set(df.columns)):
            st.error("CSV kolonlarÄ± eksik. Gerekli: phone, name, daire_id, file_url")
            st.stop()

        send_results = []
        progress = st.progress(0)
        total = len(df)
        success_cnt = 0
        fail_cnt = 0

        for i, row in df.iterrows():
            to = _ok_number(row.get("phone", ""))
            name = row.get("name","")
            did  = row.get("daire_id","")
            furl = row.get("file_url","")

            # 1) Åablonla baÅŸlat
            try:
                r1 = send_template(wa_token, phone_number_id, to, template_name, template_lang, name, did, furl, header_doc=header_document)
                if r1.ok:
                    success = True
                    info = "template OK"
                else:
                    success = False
                    info = f"template ERR {r1.status_code}: {r1.text}"
            except Exception as e:
                success = False
                info = f"template EXC: {e}"
            send_results.append({"to": to, "step": "template", "ok": success, "info": info})
            success_cnt += 1 if success else 0
            fail_cnt    += 0 if success else 1

            # 2) Pencere aÃ§Ä±ksa follow-up (opsiyonel)
            if success:
                # kÃ¼Ã§Ã¼k bekleme (rate limit / ordering)
                time.sleep(0.4)
                if send_followup_text and followup_text:
                    try:
                        msg = followup_text.format(name=name, daire_id=did, file_url=furl)
                    except Exception:
                        msg = followup_text
                    r2 = send_text(wa_token, phone_number_id, to, msg)
                    send_results.append({"to": to, "step": "text", "ok": r2.ok, "info": ("" if r2.ok else f"{r2.status_code}: {r2.text}")})
                    time.sleep(0.3)
                if send_document and furl:
                    cap = f"{did} bildirimi"
                    r3 = send_document_msg(wa_token, phone_number_id, to, furl, cap)
                    send_results.append({"to": to, "step": "document", "ok": r3.ok, "info": ("" if r3.ok else f"{r3.status_code}: {r3.text}")})
                    time.sleep(0.3)

            progress.progress((i+1)/total)

        st.success(f"GÃ¶nderim bitti. BaÅŸarÄ±lÄ±: {success_cnt}, HatalÄ±: {fail_cnt}")
        st.dataframe(pd.DataFrame(send_results), use_container_width=True)
